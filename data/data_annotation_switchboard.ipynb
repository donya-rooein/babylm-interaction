{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "932bacd9",
   "metadata": {},
   "source": [
    "# Preliminary Data Annotation\n",
    "\n",
    "We want positive/negative examples annotated with a series of linguistic metrics (coherence, fluency) both at the utterance level and at the dialogue level (< 5 turns). \n",
    "\n",
    "- Positive examples will be taken from the [BabyLM (Switchboard)](https://huggingface.co/datasets/hhoangphuoc/switchboard) dataset.\n",
    "- Negative examples will be taken from BabyLlama outputs.\n",
    "\n",
    "Corpus size: no more than 20 million tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f704407",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee1b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rooein/anaconda3/envs/babylm_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import spacy\n",
    "import contextualSpellCheck\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40262fe1",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c8a70",
   "metadata": {},
   "source": [
    "### 2.1 BabyLM (Switchboard) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4f33c",
   "metadata": {},
   "source": [
    "#### 2.1.1 Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0fdd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in switchboard.train (GPT-3.5-turbo tokenization): 2005481\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from token_count import TokenCount\n",
    "\n",
    "# Initialize TokenCount for the GPT-3.5-turbo model\n",
    "tc = TokenCount(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "# === Load and Clean Data ===\n",
    "with open(\"./train_100M/switchboard.train\", \"r\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip() and not line.startswith(\"----\")]\n",
    "\n",
    "# Compute and print total token count using TokenCount\n",
    "text_content = \" \".join(lines)\n",
    "total_tokens = tc.num_tokens_from_string(text_content)\n",
    "print(f\"Total tokens in switchboard.train (GPT-3.5-turbo tokenization): {total_tokens}\")\n",
    "\n",
    "# Parse speaker and text\n",
    "data = []\n",
    "for line in lines:\n",
    "    if \"\\t\" in line:\n",
    "        speaker, text = line.split(\"\\t\", 1)\n",
    "        data.append((speaker.strip(), text.strip()))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"speaker\", \"text\"])\n",
    "\n",
    "# === Dialog-Level Chunking (5-turn blocks like ABABA or BABAB) ===\n",
    "dialogs = []\n",
    "current_dialog = []\n",
    "last_speaker = None\n",
    "\n",
    "for speaker, text in zip(df[\"speaker\"], df[\"text\"]):\n",
    "    if not current_dialog:\n",
    "        current_dialog.append([speaker, [text]])\n",
    "    elif speaker == last_speaker:\n",
    "        current_dialog[-1][1].append(text)\n",
    "    else:\n",
    "        current_dialog.append([speaker, [text]])\n",
    "\n",
    "    last_speaker = speaker\n",
    "\n",
    "    if len(current_dialog) == 5:\n",
    "        dialog_text = [f\"{turn[0]}: {' '.join(turn[1])}\" for turn in current_dialog]\n",
    "        dialogs.append(dialog_text)\n",
    "        current_dialog = []\n",
    "        last_speaker = None\n",
    "\n",
    "# Convert to DataFrame\n",
    "dialog_df = pd.DataFrame(dialogs, columns=[f\"turn_{i+1}\" for i in range(5)])\n",
    "\n",
    "# === Save DataFrames ===\n",
    "dialog_df.to_csv(\"switchboard_dialog_level.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93b5b595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161740"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a80e595",
   "metadata": {},
   "source": [
    "## 3. Metrics\n",
    "\n",
    "We discussed Fluency and Coherence as the two important things we want to annotate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc9d0a",
   "metadata": {},
   "source": [
    "### 3.1 TAACO metrics \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Loading TAACO Outputs for Dialogs\n",
    "\n",
    "TAACO accepts inputs as `.txt` files. To prepare inputs for TAACO, we first chunk the dataset into individual turns using the `switchboard_data`, and save each dialog separately as `.txt` files in the directory `dialog_level_texts`.\n",
    "\n",
    "Next, we run TAACO metrics on these text files by executing `test_donya.py` located in the TAACO directory. TAACO outputs are then saved to the directory `switchboard_results`.\n",
    "\n",
    "We subsequently filter the TAACO outputs, retaining only the following selected metrics:\n",
    "\n",
    "- `noun_ttr`\n",
    "- `verb_ttr`\n",
    "- `adj_ttr`\n",
    "- `lemma_ttr`\n",
    "- `bigram_lemma_ttr`\n",
    "- `trigram_lemma_ttr`\n",
    "- `adjacent_overlap_all_sent`\n",
    "- `lda_1_all_sent`\n",
    "- `repeated_content_lemmas`\n",
    "- `repeated_content_and_pronoun_lemmas`\n",
    "\n",
    "Finally, we rank the dialog texts by token length to prioritize longer dialogs, aiming for a final corpus size of approximately **30 million tokens**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e7eb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens before ranking: 1269754\n",
      "Total tokens after ranking and selection: 1269754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>noun_ttr</th>\n",
       "      <th>verb_ttr</th>\n",
       "      <th>adj_ttr</th>\n",
       "      <th>lemma_ttr</th>\n",
       "      <th>bigram_lemma_ttr</th>\n",
       "      <th>trigram_lemma_ttr</th>\n",
       "      <th>adjacent_overlap_all_sent</th>\n",
       "      <th>lda_1_all_sent</th>\n",
       "      <th>repeated_content_lemmas</th>\n",
       "      <th>repeated_content_and_pronoun_lemmas</th>\n",
       "      <th>text</th>\n",
       "      <th>token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>dialog_02341.txt</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.332795</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.970827</td>\n",
       "      <td>0.191244</td>\n",
       "      <td>0.948037</td>\n",
       "      <td>0.211632</td>\n",
       "      <td>0.276252</td>\n",
       "      <td>B:: And nothing is being done about it. Uh, th...</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>dialog_02633.txt</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.336299</td>\n",
       "      <td>0.832442</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>0.979711</td>\n",
       "      <td>0.275801</td>\n",
       "      <td>0.339858</td>\n",
       "      <td>B:: I don't know if any of mine will be intere...</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>dialog_08707.txt</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.786948</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.203166</td>\n",
       "      <td>0.970758</td>\n",
       "      <td>0.272031</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>A:: I put a stop to some of them as far as the...</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12658</th>\n",
       "      <td>dialog_12658.txt</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.342697</td>\n",
       "      <td>0.840525</td>\n",
       "      <td>0.956767</td>\n",
       "      <td>0.182870</td>\n",
       "      <td>0.956388</td>\n",
       "      <td>0.284644</td>\n",
       "      <td>0.393258</td>\n",
       "      <td>A:: You know, my neighbors across the street, ...</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>dialog_00283.txt</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.355509</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.960334</td>\n",
       "      <td>0.250737</td>\n",
       "      <td>0.969054</td>\n",
       "      <td>0.251559</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>A:: Yeah. Have you, do you use a standard, uh,...</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Filename  noun_ttr  verb_ttr   adj_ttr  lemma_ttr  \\\n",
       "2341   dialog_02341.txt  0.710000  0.475000  0.857143   0.332795   \n",
       "2633   dialog_02633.txt  0.659794  0.486842  0.657143   0.336299   \n",
       "8707   dialog_08707.txt  0.680000  0.463415  0.750000   0.321839   \n",
       "12658  dialog_12658.txt  0.621622  0.432432  0.787879   0.342697   \n",
       "283    dialog_00283.txt  0.708861  0.538462  0.692308   0.355509   \n",
       "\n",
       "       bigram_lemma_ttr  trigram_lemma_ttr  adjacent_overlap_all_sent  \\\n",
       "2341           0.815534           0.970827                   0.191244   \n",
       "2633           0.832442           0.978571                   0.217778   \n",
       "8707           0.786948           0.938462                   0.203166   \n",
       "12658          0.840525           0.956767                   0.182870   \n",
       "283            0.816667           0.960334                   0.250737   \n",
       "\n",
       "       lda_1_all_sent  repeated_content_lemmas  \\\n",
       "2341         0.948037                 0.211632   \n",
       "2633         0.979711                 0.275801   \n",
       "8707         0.970758                 0.272031   \n",
       "12658        0.956388                 0.284644   \n",
       "283          0.969054                 0.251559   \n",
       "\n",
       "       repeated_content_and_pronoun_lemmas  \\\n",
       "2341                              0.276252   \n",
       "2633                              0.339858   \n",
       "8707                              0.362069   \n",
       "12658                             0.393258   \n",
       "283                               0.361746   \n",
       "\n",
       "                                                    text  token_length  \n",
       "2341   B:: And nothing is being done about it. Uh, th...           598  \n",
       "2633   B:: I don't know if any of mine will be intere...           547  \n",
       "8707   A:: I put a stop to some of them as far as the...           497  \n",
       "12658  A:: You know, my neighbors across the street, ...           494  \n",
       "283    A:: Yeah. Have you, do you use a standard, uh,...           465  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "csv_file_path = '/home/rooein/BabyLM/babylm-interaction/baseline/data/switchboard_results_filtered/dialog_level_taaco_results.csv'\n",
    "texts_folder_path = '/home/rooein/BabyLM/babylm-interaction/baseline/data/switchboard_taaco_input/dialog_level_texts'\n",
    "output_csv_path = '/home/rooein/BabyLM/babylm-interaction/baseline/data/switchboard_results_filtered/dialog_level_taaco_with_text_30M.csv'\n",
    "\n",
    "# Step 1: Load CSV\n",
    "metrics_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Step 2: Load and map text files to filenames\n",
    "def load_text(filename, folder):\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "# Add text column based on Filename\n",
    "metrics_df['text'] = metrics_df['Filename'].apply(lambda fname: load_text(fname, texts_folder_path))\n",
    "\n",
    "# Step 3: Compute token length and rank texts\n",
    "metrics_df['token_length'] = metrics_df['text'].apply(lambda x: len(x.split()))\n",
    "print(f\"Total tokens before ranking: {metrics_df['token_length'].sum()}\")\n",
    "\n",
    "metrics_df.sort_values(by='token_length', ascending=False, inplace=True)\n",
    "\n",
    "# Step 4: Select data until reaching approximately 30 million tokens\n",
    "max_tokens = 30_000_000\n",
    "token_count = 0\n",
    "selected_rows = []\n",
    "\n",
    "for idx, row in metrics_df.iterrows():\n",
    "    if token_count + row['token_length'] <= max_tokens:\n",
    "        selected_rows.append(row)\n",
    "        token_count += row['token_length']\n",
    "    else:\n",
    "        break\n",
    "\n",
    "selected_df = pd.DataFrame(selected_rows)\n",
    "\n",
    "print(f\"Total tokens after ranking and selection: {selected_df['token_length'].sum()}\")\n",
    "\n",
    "# Step 5: Save the final DataFrame\n",
    "selected_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "selected_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c602f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'noun_ttr', 'verb_ttr', 'adj_ttr', 'lemma_ttr',\n",
       "       'bigram_lemma_ttr', 'trigram_lemma_ttr', 'adjacent_overlap_all_sent',\n",
       "       'lda_1_all_sent', 'repeated_content_lemmas',\n",
       "       'repeated_content_and_pronoun_lemmas', 'text', 'token_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c9a804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Filename                                               text  \\\n",
      "2341   dialog_02341.txt  B:: And nothing is being done about it. Uh, th...   \n",
      "2633   dialog_02633.txt  B:: I don't know if any of mine will be intere...   \n",
      "8707   dialog_08707.txt  A:: I put a stop to some of them as far as the...   \n",
      "12658  dialog_12658.txt  A:: You know, my neighbors across the street, ...   \n",
      "283    dialog_00283.txt  A:: Yeah. Have you, do you use a standard, uh,...   \n",
      "\n",
      "       token_length                                      TAACO_metrics  \n",
      "2341            598  {'noun_ttr': 0.71, 'verb_ttr': 0.475, 'adj_ttr...  \n",
      "2633            547  {'noun_ttr': 0.6597938144329897, 'verb_ttr': 0...  \n",
      "8707            497  {'noun_ttr': 0.68, 'verb_ttr': 0.4634146341463...  \n",
      "12658           494  {'noun_ttr': 0.6216216216216216, 'verb_ttr': 0...  \n",
      "283             465  {'noun_ttr': 0.7088607594936709, 'verb_ttr': 0...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = selected_df\n",
    "\n",
    "# Define TAACO metrics columns\n",
    "taaco_cols = [\n",
    "    'noun_ttr', 'verb_ttr', 'adj_ttr', 'lemma_ttr',\n",
    "    'bigram_lemma_ttr', 'trigram_lemma_ttr', 'adjacent_overlap_all_sent',\n",
    "    'lda_1_all_sent', 'repeated_content_lemmas',\n",
    "    'repeated_content_and_pronoun_lemmas'\n",
    "]\n",
    "\n",
    "# Create new column with TAACO metrics as a dictionary\n",
    "df['TAACO_metrics'] = df[taaco_cols].to_dict(orient='records')\n",
    "\n",
    "# Keep only the desired columns\n",
    "df_reformatted = df[['Filename', 'text', 'token_length', 'TAACO_metrics']]\n",
    "\n",
    "# Display or save the new DataFrame\n",
    "print(df_reformatted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b35fdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>text</th>\n",
       "      <th>token_length</th>\n",
       "      <th>TAACO_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>dialog_02341.txt</td>\n",
       "      <td>B:: And nothing is being done about it. Uh, th...</td>\n",
       "      <td>598</td>\n",
       "      <td>{'noun_ttr': 0.71, 'verb_ttr': 0.475, 'adj_ttr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>dialog_02633.txt</td>\n",
       "      <td>B:: I don't know if any of mine will be intere...</td>\n",
       "      <td>547</td>\n",
       "      <td>{'noun_ttr': 0.6597938144329897, 'verb_ttr': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>dialog_08707.txt</td>\n",
       "      <td>A:: I put a stop to some of them as far as the...</td>\n",
       "      <td>497</td>\n",
       "      <td>{'noun_ttr': 0.68, 'verb_ttr': 0.4634146341463...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12658</th>\n",
       "      <td>dialog_12658.txt</td>\n",
       "      <td>A:: You know, my neighbors across the street, ...</td>\n",
       "      <td>494</td>\n",
       "      <td>{'noun_ttr': 0.6216216216216216, 'verb_ttr': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>dialog_00283.txt</td>\n",
       "      <td>A:: Yeah. Have you, do you use a standard, uh,...</td>\n",
       "      <td>465</td>\n",
       "      <td>{'noun_ttr': 0.7088607594936709, 'verb_ttr': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>dialog_01093.txt</td>\n",
       "      <td>A:: Yeah.\\nB:: and,\\nA:: Uh-huh.\\nB:: I don't ...</td>\n",
       "      <td>12</td>\n",
       "      <td>{'noun_ttr': 0.4, 'verb_ttr': 1.0, 'adj_ttr': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672</th>\n",
       "      <td>dialog_10672.txt</td>\n",
       "      <td>B:: Uh-huh.\\nA:: Small island.\\nB:: Yeah.\\nA::...</td>\n",
       "      <td>11</td>\n",
       "      <td>{'noun_ttr': 0.5, 'verb_ttr': 0.0, 'adj_ttr': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>dialog_06125.txt</td>\n",
       "      <td>A:: Thanks.\\nB:: Thank you.\\nA:: Bye.\\nB:: Goo...</td>\n",
       "      <td>11</td>\n",
       "      <td>{'noun_ttr': 0.5, 'verb_ttr': 1.0, 'adj_ttr': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13613</th>\n",
       "      <td>dialog_13613.txt</td>\n",
       "      <td>A:: Okay.\\nB:: Thanks.\\nA:: Thank you.\\nB:: By...</td>\n",
       "      <td>11</td>\n",
       "      <td>{'noun_ttr': 0.4444444444444444, 'verb_ttr': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15751</th>\n",
       "      <td>dialog_15751.txt</td>\n",
       "      <td>A:: Oh,\\nB:: And,\\nA:: yeah.\\nB:: It,\\nA:: They</td>\n",
       "      <td>10</td>\n",
       "      <td>{'noun_ttr': 0.4, 'verb_ttr': 0.0, 'adj_ttr': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17893 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Filename                                               text  \\\n",
       "2341   dialog_02341.txt  B:: And nothing is being done about it. Uh, th...   \n",
       "2633   dialog_02633.txt  B:: I don't know if any of mine will be intere...   \n",
       "8707   dialog_08707.txt  A:: I put a stop to some of them as far as the...   \n",
       "12658  dialog_12658.txt  A:: You know, my neighbors across the street, ...   \n",
       "283    dialog_00283.txt  A:: Yeah. Have you, do you use a standard, uh,...   \n",
       "...                 ...                                                ...   \n",
       "1093   dialog_01093.txt  A:: Yeah.\\nB:: and,\\nA:: Uh-huh.\\nB:: I don't ...   \n",
       "10672  dialog_10672.txt  B:: Uh-huh.\\nA:: Small island.\\nB:: Yeah.\\nA::...   \n",
       "6125   dialog_06125.txt  A:: Thanks.\\nB:: Thank you.\\nA:: Bye.\\nB:: Goo...   \n",
       "13613  dialog_13613.txt  A:: Okay.\\nB:: Thanks.\\nA:: Thank you.\\nB:: By...   \n",
       "15751  dialog_15751.txt    A:: Oh,\\nB:: And,\\nA:: yeah.\\nB:: It,\\nA:: They   \n",
       "\n",
       "       token_length                                      TAACO_metrics  \n",
       "2341            598  {'noun_ttr': 0.71, 'verb_ttr': 0.475, 'adj_ttr...  \n",
       "2633            547  {'noun_ttr': 0.6597938144329897, 'verb_ttr': 0...  \n",
       "8707            497  {'noun_ttr': 0.68, 'verb_ttr': 0.4634146341463...  \n",
       "12658           494  {'noun_ttr': 0.6216216216216216, 'verb_ttr': 0...  \n",
       "283             465  {'noun_ttr': 0.7088607594936709, 'verb_ttr': 0...  \n",
       "...             ...                                                ...  \n",
       "1093             12  {'noun_ttr': 0.4, 'verb_ttr': 1.0, 'adj_ttr': ...  \n",
       "10672            11  {'noun_ttr': 0.5, 'verb_ttr': 0.0, 'adj_ttr': ...  \n",
       "6125             11  {'noun_ttr': 0.5, 'verb_ttr': 1.0, 'adj_ttr': ...  \n",
       "13613            11  {'noun_ttr': 0.4444444444444444, 'verb_ttr': 1...  \n",
       "15751            10  {'noun_ttr': 0.4, 'verb_ttr': 0.0, 'adj_ttr': ...  \n",
       "\n",
       "[17893 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8fa7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_reformatted to csv\n",
    "output_csv_path = '/home/rooein/BabyLM/babylm-interaction/baseline/data/switchboard_results_filtered/dialog_level_taaco_reformatted.csv'\n",
    "df_reformatted.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcab70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
